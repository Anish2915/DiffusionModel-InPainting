{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1cd5764-63ab-409a-8fc9-ddd947422d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First put that image in location ./Image_you_want_to_use \n",
      "after that two window will open, you can paint mask on that selected image whatever part you want to remove and whenever you are done then simply press d\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import conf_mgt\n",
    "from utils import yamlread\n",
    "from guided_diffusion import dist_util\n",
    "\n",
    "try:\n",
    "    import ctypes\n",
    "    libgcc_s = ctypes.CDLL('libgcc_s.so.1')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "from guided_diffusion.script_util import (\n",
    "    NUM_CLASSES,\n",
    "    model_and_diffusion_defaults,\n",
    "    classifier_defaults,\n",
    "    create_model_and_diffusion,\n",
    "    create_classifier,\n",
    "    select_args,\n",
    ")\n",
    "\n",
    "def toU8(sample):\n",
    "    if sample is None:\n",
    "        return sample\n",
    "\n",
    "    sample = ((sample + 1) * 127.5).clamp(0, 255).to(th.uint8)\n",
    "    sample = sample.permute(0, 2, 3, 1)\n",
    "    sample = sample.contiguous()\n",
    "    sample = sample.detach().cpu().numpy()\n",
    "    return sample\n",
    "\n",
    "def main(conf_path):\n",
    "\n",
    "    conf = conf_mgt.conf_base.Default_Conf()\n",
    "    conf.update(yamlread(conf_path))\n",
    "\n",
    "    print(\"Start\", conf['name'])\n",
    "\n",
    "    device = dist_util.dev(conf.get('device'))\n",
    "\n",
    "    model, diffusion = create_model_and_diffusion(\n",
    "        **select_args(conf, model_and_diffusion_defaults().keys()), conf=conf\n",
    "    )\n",
    "    model.load_state_dict(\n",
    "        dist_util.load_state_dict(os.path.expanduser(\n",
    "            conf.model_path), map_location=\"cpu\")\n",
    "    )\n",
    "    model.to(device)\n",
    "    if conf.use_fp16:\n",
    "        model.convert_to_fp16()\n",
    "    model.eval()\n",
    "\n",
    "    show_progress = conf.show_progress\n",
    "\n",
    "    if conf.classifier_scale > 0 and conf.classifier_path:\n",
    "        print(\"loading classifier...\")\n",
    "        classifier = create_classifier(\n",
    "            **select_args(conf, classifier_defaults().keys()))\n",
    "        classifier.load_state_dict(\n",
    "            dist_util.load_state_dict(os.path.expanduser(\n",
    "                conf.classifier_path), map_location=\"cpu\")\n",
    "        )\n",
    "\n",
    "        classifier.to(device)\n",
    "        if conf.classifier_use_fp16:\n",
    "            classifier.convert_to_fp16()\n",
    "        classifier.eval()\n",
    "\n",
    "        def cond_fn(x, t, y=None, gt=None, **kwargs):\n",
    "            assert y is not None\n",
    "            with th.enable_grad():\n",
    "                x_in = x.detach().requires_grad_(True)\n",
    "                logits = classifier(x_in, t)\n",
    "                log_probs = F.log_softmax(logits, dim=-1)\n",
    "                selected = log_probs[range(len(logits)), y.view(-1)]\n",
    "                return th.autograd.grad(selected.sum(), x_in)[0] * conf.classifier_scale\n",
    "    else:\n",
    "        cond_fn = None\n",
    "\n",
    "    def model_fn(x, t, y=None, gt=None, **kwargs):\n",
    "        assert y is not None\n",
    "        return model(x, t, y if conf.class_cond else None, gt=gt)\n",
    "\n",
    "    print(\"sampling...\")\n",
    "    all_images = []\n",
    "\n",
    "    dset = 'eval'\n",
    "\n",
    "    eval_name = conf.get_default_eval_name()\n",
    "\n",
    "    dl = conf.get_dataloader(dset=dset, dsName=eval_name)\n",
    "    print(len(dl)) \n",
    "    for batch in iter(dl):\n",
    "\n",
    "        for k in batch.keys():\n",
    "            if isinstance(batch[k], th.Tensor):\n",
    "                batch[k] = batch[k].to(device)\n",
    "\n",
    "        model_kwargs = {}\n",
    "\n",
    "        model_kwargs[\"gt\"] = batch['GT']\n",
    "\n",
    "        gt_keep_mask = batch.get('gt_keep_mask')\n",
    "        if gt_keep_mask is not None:\n",
    "            model_kwargs['gt_keep_mask'] = gt_keep_mask\n",
    "\n",
    "        batch_size = model_kwargs[\"gt\"].shape[0]\n",
    "\n",
    "        if conf.cond_y is not None:\n",
    "            classes = th.ones(batch_size, dtype=th.long, device=device)\n",
    "            model_kwargs[\"y\"] = classes * conf.cond_y\n",
    "        else:\n",
    "            classes = th.randint(\n",
    "                low=0, high=NUM_CLASSES, size=(batch_size,), device=device\n",
    "            )\n",
    "            model_kwargs[\"y\"] = classes\n",
    "\n",
    "        sample_fn = (\n",
    "            diffusion.p_sample_loop if not conf.use_ddim else diffusion.ddim_sample_loop\n",
    "        )\n",
    "\n",
    "\n",
    "        result = sample_fn(\n",
    "            model_fn,\n",
    "            (batch_size, 3, conf.image_size, conf.image_size),\n",
    "            clip_denoised=conf.clip_denoised,\n",
    "            model_kwargs=model_kwargs,\n",
    "            cond_fn=cond_fn,\n",
    "            device=device,\n",
    "            progress=show_progress,\n",
    "            return_all=True,\n",
    "            conf=conf\n",
    "        )\n",
    "        srs = toU8(result['sample'])\n",
    "        gts = toU8(result['gt'])\n",
    "        lrs = toU8(result.get('gt') * model_kwargs.get('gt_keep_mask') + (-1) *\n",
    "                   th.ones_like(result.get('gt')) * (1 - model_kwargs.get('gt_keep_mask')))\n",
    "\n",
    "        gt_keep_masks = toU8((model_kwargs.get('gt_keep_mask') * 2 - 1))\n",
    "\n",
    "        conf.eval_imswrite(\n",
    "            srs=srs, gts=gts, lrs=lrs, gt_keep_masks=gt_keep_masks,\n",
    "            img_names=batch['GT_name'], dset=dset, name=eval_name, verify_same=False)\n",
    "\n",
    "    print(\"sampling complete, now check output in ./output folder\")\n",
    "\n",
    "print(\"First put that image in location ./Image_you_want_to_use \")\n",
    "print(\"after that two window will open, you can paint mask on that selected image whatever part you want to remove and whenever you are done then simply press d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d09c98a0-4040-4c84-9183-83e4dc796309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the name of the image file which is in the location './Image you want to use' (including extension):  test.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask saved as ./Image Mask You Want to use/mask.jpg\n",
      "Make sure you have only 1-1 image in location './Image Mask you want to use ' and './Image you want to use' \n",
      "If you want to use sample mask then you can simply take that mask image from ./data/dataset/() and paste in Image mask you want to use\n"
     ]
    }
   ],
   "source": [
    "def resize_image(image):\n",
    "    return cv2.resize(image, (256, 256))\n",
    "\n",
    "def paint(event, x, y, flags, param):\n",
    "    global drawing\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        cv2.circle(selected_image, (x, y), brush_size, (0, 0, 0), -1)\n",
    "        cv2.circle(white_image, (x, y), brush_size, (0, 0, 0), -1)\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if drawing:\n",
    "            cv2.circle(selected_image, (x, y), brush_size, (0, 0, 0), -1)\n",
    "            cv2.circle(white_image, (x, y), brush_size, (0, 0, 0), -1)\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "\n",
    "selected_image_filename = input(\"Enter the name of the image file which is in the location './Image you want to use' (including extension): \")\n",
    "selected_image_path = os.path.join(\"./Image you want to use/\", selected_image_filename)\n",
    "selected_image = cv2.imread(selected_image_path)\n",
    "if selected_image is None:\n",
    "    print(\"Error: Image not found or could not be opened.\")\n",
    "    exit()\n",
    "\n",
    "selected_image = resize_image(selected_image)\n",
    "cv2.imwrite(selected_image_path, selected_image)\n",
    "\n",
    "white_image = np.ones_like(selected_image) * 255\n",
    "\n",
    "drawing = False\n",
    "brush_size = 5\n",
    "\n",
    "cv2.namedWindow('Painting')\n",
    "cv2.namedWindow('Selected Image')\n",
    "\n",
    "cv2.setMouseCallback('Selected Image', paint)\n",
    "\n",
    "while True:\n",
    "    cv2.imshow('Selected Image', selected_image)\n",
    "    cv2.imshow('Painting', white_image)\n",
    "    \n",
    "    # Check for key press\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('d'):\n",
    "        mask_filename = \"mask.jpg\"\n",
    "        mask_path = os.path.join(\"./Image Mask You Want to use/\", mask_filename)\n",
    "        cv2.imwrite(mask_path, white_image)\n",
    "        print(\"Mask saved as\", mask_path)\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Make sure you have only 1-1 image in location './Image Mask you want to use ' and './Image you want to use' \")\n",
    "print(\"If you want to use sample mask then you can simply take that mask image from ./data/dataset/() and paste in Image mask you want to use\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8526949-5db9-4a68-bc04-f0e591a0fc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "if your image contain human then press 1 otherwise press 2  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration path is: Real.yml\n"
     ]
    }
   ],
   "source": [
    "# Take an integer input from the user\n",
    "user_input = int(input(\"if your image contain human then press 1 otherwise press 2 \"))\n",
    "\n",
    "# Check the user's input and set the conf_path accordingly\n",
    "if user_input == 1:\n",
    "    conf_path = \"Real.yml\"\n",
    "elif user_input == 2:\n",
    "    conf_path = \"Real2.yml\"\n",
    "else:\n",
    "    print(\"Invalid input. Please enter either 1 or 2.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Configuration path is:\", conf_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b415fa6b-50ae-4ce8-b29e-041f7d1b9257",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main(conf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa1da75-9fcc-47f1-9019-a3a78d6f7111",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
